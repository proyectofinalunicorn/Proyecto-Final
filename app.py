import pandas as pd
import numpy as np
import yfinance as yf
import requests
import streamlit as st
import os
from datetime import datetime
from sqlalchemy import create_engine, MetaData, Table, Column, String, Date, Float, Integer, Text, text, PrimaryKeyConstraint
from sqlalchemy.pool import NullPool

if 'procesamiento_listo' not in st.session_state:
    st.session_state.procesamiento_listo = False
if 'ultimo_mensaje' not in st.session_state:
    st.session_state.ultimo_mensaje = ""

def procesar_y_guardar_en_sql(archivo_subido, db_host, db_name, db_user, db_pass):
    try:
        ##IMPORTACION DE BASE DE DATOS
        st.write(f"Leyendo archivo: {archivo_subido.name}...")
        if archivo_subido.name.endswith(('.xlsx')):
            df = pd.read_excel(archivo_subido, sheet_name="resultados_por_lotes_finales")
        else:
            st.error("Error: Formato de archivo no soportado.")
            return False, "Error de archivo"

        ##RENOMBRAR COLUMNAS
        df.rename(columns = {"Cantidad": "cantidad", "Descripcion": "descripcion", "Fecha": "fecha", "Fecha Lote": "fecha_descarga", "Gastos": "gastos", "Moneda": "moneda", "Operacion": "operacion", "Precio Compra": "precio_compra", "Ticker": "ticker", "Tipo": "tipo", "DolarCCL": "dolar_ccl", "DolarMEP": "dolar_mep", "DolarOficial": "dolar_oficial"}, inplace = True)

        ##ELIMINACIÃ“N DE COLUMNAS INNECESARIAS
        columnas_a_borrar = ["dolar_ccl", "operacion"]
        columnas_existentes = [col for col in columnas_a_borrar if col in df.columns]
        df.drop(columnas_existentes, axis=1, inplace=True)

        ##FILTRO DE DATOS POR TIPO DE ACTIVO
        df_cedears = df[df.tipo == "Cedears"].copy()

        ##CAMBIO DE TIPO DE DATO A FECHA
        df_cedears.fecha = pd.to_datetime(df_cedears.fecha)
        df_cedears.fecha_descarga = pd.to_datetime(df_cedears.fecha_descarga)
        
        # ORDENAR POR FECHA
        if "fecha" in df_cedears.columns:
            df_cedears.sort_values(by="fecha", inplace=True)
            df_cedears.reset_index(drop=True, inplace=True)
        else:
            print("Error: No se pudo ordenar por fecha")

        ##CALCULO DE COSTO EN PESOS ARGENTINOS
        df_cedears["costo_ars"] = (df_cedears.cantidad * df_cedears.precio_compra)+df_cedears.gastos

        ##CALCULO DE COSTO EN USD (SEGÃšN FECHA)
        df_cedears["costo_usd"] = np.where(
            df_cedears.fecha < pd.to_datetime("2025-04-15"),
            df_cedears.costo_ars / df_cedears.dolar_mep,
            df_cedears.costo_ars / np.minimum(df_cedears.dolar_oficial, df_cedears.dolar_mep)
        )

        ## LISTA UNICA DE ACCIONES
        tickers_unicos = df_cedears.ticker.unique()

        ## CREACIÃ“N DE DICCIONARIO PARA LA COTIZACION ACTUAL
        cotizacion_actual = {}
        st.write("Obteniendo cotizaciones...")

        ## COTIZACION ACTUALIZADA
        for ticker in tickers_unicos:
            ticker_argentina = ticker + ".BA"
            try:
                ticker_obj = yf.Ticker(ticker_argentina)
                info = ticker_obj.info
                if 'regularMarketPrice' in info and info['regularMarketPrice'] is not None:
                    precio = info['regularMarketPrice']
                else:
                    precio = ticker_obj.fast_info["last_price"]
                cotizacion_actual[ticker] = precio
            except Exception as e:
                st.warning(f"Error al obtener la cotizaciÃ³n de {ticker}: {e}")

        ## CALCULO DE TENENCIA TOTAL ACTUALIZADA EN PESOS ARGENTINOS
        df_cedears["tenencia_ars"] = (df_cedears.cantidad * df_cedears.ticker.map(cotizacion_actual).fillna(0))*(1-0.006)

        ## CREACION DE FUNCION PARA OBTENER VALOR DE DOLAR ACTUALIZADO
        def obtener_valores_dolar():
            api_url = "https://dolarapi.com/v1/dolares"
            try:
                response = requests.get(api_url)
                response.raise_for_status()
                data = response.json()
                df_dolar_api = pd.DataFrame(data)
                valor_oficial = df_dolar_api.loc[df_dolar_api['casa'] == 'oficial', 'venta'].values[0]
                valor_mep = df_dolar_api.loc[df_dolar_api['casa'] == 'bolsa', 'venta'].values[0]
                return valor_oficial, valor_mep
            except Exception as e:
                st.error(f"Error al cargar valores de dÃ³lar: {e}")
                return None, None

        ## EJECUCIÃ“N DE LA FUNCIÃ“N
        st.write("Obteniendo valor del dÃ³lar...")
        dolar_oficial, dolar_mep = obtener_valores_dolar()
        if dolar_oficial is None or dolar_mep is None:
            raise Exception("No se pudo obtener el valor del dÃ³lar, el proceso no puede continuar.")

        ## CALCULO DE TENENCIA TOTAL ACTUALIZADA EN USD (utilizando el tipo de cambio mas bajo)
        df_cedears["tenencia_usd"] = df_cedears.tenencia_ars / np.minimum(dolar_oficial, dolar_mep)

        ## CÃLCULO DE GANANCIA O PERDIDA EN PESOS ARGENTINOS
        df_cedears["resultados_ars"] = df_cedears.tenencia_ars - df_cedears.costo_ars

        ## CÃLCULO DE GANANCIA O PERDIDA EN DOLARES
        df_cedears["resultados_usd"] = df_cedears.tenencia_usd - df_cedears.costo_usd

        ## CÃLCULO DE RENDIMIENTO PORCENTUAL EN PESOS ARGENTINOS
        df_cedears["rendimiento_ars"] = round((df_cedears.tenencia_ars / df_cedears.costo_ars - 1) * 100, 2)

        ## CÃLCULO DE RENDIMIENTO PORCENTUAL EN DOLARES
        df_cedears["rendimiento_usd"] = round((df_cedears.tenencia_usd / df_cedears.costo_usd - 1) * 100, 2)

        ## AGRUPACION DE ACCIONES Y TOTALES
        df_cedears_analisis = df_cedears[["ticker", "cantidad", "costo_ars","costo_usd","tenencia_ars",	"tenencia_usd", "resultados_ars",	"resultados_usd"]]
        df_cedears_agrupado = df_cedears_analisis.groupby("ticker").sum().round(2)
        df_cedears_agrupado["rendimiento_ars"] = df_cedears_agrupado["resultados_ars"] / df_cedears_agrupado["costo_ars"]
        df_cedears_agrupado["rendimiento_usd"] = df_cedears_agrupado["resultados_usd"] / df_cedears_agrupado["costo_usd"]
        df_cedears_agrupado.reset_index(inplace=True)

        ## MODIFICACION DEL DATAFRAME PARA FILTRAR POR MONEDA
        # AÃ‘ADIR FECHA DE EJECUCIÃ“N
        df_cedears_agrupado['fecha_ejecucion'] = datetime.now().date()

        # MODIFICACIÃ“N PARA INCLUIR TIPO DE MONEDA
        try:
            df_final_largo = pd.wide_to_long(
                df_cedears_agrupado,
                # PREFIJO DE COLUMNA
                stubnames=['costo', 'tenencia', 'resultados', 'rendimiento'],
                # COLUMNAS QUE NO DEBEN PIVOTARSE
                i=['ticker', 'cantidad', 'fecha_ejecucion'],
                # CREACION DE COLUMNA POR TIPO DE MONEDA
                j='moneda',
                # CONECTOR ENTRE PREFIJO Y SUFIJO
                sep='_',
                # SUFIJO DE COLUMNA
                suffix='(ars|usd)'
            )
            # RESET DE INDICES
            df_final_listo = df_final_largo.reset_index()
        except Exception as e:
            st.error(f"Error en wide_to_long: {e}")
            raise e

        ## DATOS DE CONEXION A SUPABASE (SQL)
        st.write("Conectando a la base de datos...")
        user = db_user
        password = db_pass
        database = db_name
        pooler_host = db_host
        pooler_port = '5432'

        ## GUARDADO DE DF_CEDEARS CON PRIMARYKEY EN SUPABASE (SQL)
        # CONEXION A SQL
        connection_url = f'postgresql+psycopg2://{user}:{password}@{pooler_host}:{pooler_port}/{database}?sslmode=require'

        try:
            engine = create_engine(connection_url, poolclass=NullPool)
            with engine.begin() as connection:
                # ESTRUCTURA DE LA TABLA
                metadata = MetaData()
                table_name = 'cedears'
                cedears_table = Table(
                    table_name,
                    metadata,
                    Column('id_operacion', Integer, primary_key=True, autoincrement=True),
                    Column('cantidad', Float),
                    Column('descripcion', Text),
                    Column('fecha', Date),
                    Column('fecha_descarga', Date),
                    Column('gastos', Float),
                    Column('moneda', String),
                    Column('precio_compra', Float),
                    Column('ticker', String),
                    Column('tipo', String),
                    Column('dolar_mep', Float),
                    Column('dolar_oficial', Float),
                    Column('costo_ars', Float),
                    Column('costo_usd', Float),
                    Column('tenencia_ars', Float),
                    Column('tenencia_usd', Float),
                    Column('resultados_ars', Float),
                    Column('resultados_usd', Float),
                    Column('rendimiento_ars', Float),
                    Column('rendimiento_usd', Float)
                )
                metadata.create_all(engine)
                st.write(f"Tabla '{table_name}' creada.")

                # ELIMINACION DE DATOS
                connection.execute(text(f"TRUNCATE TABLE {table_name} RESTART IDENTITY;"))
                # INSERCIÃ“N DE DATOS
                df_cedears.to_sql(
                    table_name,
                    connection,
                    if_exists='append',
                    index=False
                )
        except Exception as e:
            raise e

        ## GUARDADO DE DATOS HISTORICOS
        # CONEXION A SQL
        connection_url_hist = f'postgresql+psycopg2://{user}:{password}@{pooler_host}:{pooler_port}/{database}?sslmode=require'

        try:
            engine_hist = create_engine(connection_url_hist, poolclass=NullPool)
            # ESTRUCTURA DE LA TABLA
            metadata_hist = MetaData()
            table_name_hist = 'datos_historicos_cedears'
            historico_table = Table(
                table_name_hist,
                metadata_hist,
                Column('ticker', String, primary_key=True),
                Column('cantidad', Float),
                Column('fecha_ejecucion', Date, primary_key=True),
                Column('moneda', String, primary_key=True),
                Column('costo', Float),
                Column('tenencia', Float),
                Column('resultados', Float),
                Column('rendimiento', Float)
            )
            # Drop and recreate the table to ensure schema is updated
            metadata_hist.drop_all(engine_hist)
            metadata_hist.create_all(engine_hist)
            st.write(f"Tabla '{table_name_hist}' creada.")

            with engine_hist.connect() as connection:
                # INSERCIÃ“N DE DATOS
                try:
                    if 'df_final_listo' not in locals():
                        st.warning("No existe df_final_listo, omitiendo carga de datos histÃ³ricos.")
                    else:
                        df_final_listo.to_sql(
                            table_name_hist,
                            connection,
                            if_exists='append',
                            index=False
                        )
                except Exception as ex:
                    # COMPROBACIÃ“N DE DATOS DUPLICADOS
                    if "violates unique constraint" in str(ex) or "duplicate key value" in str(ex):
                        st.warning(f"Advertencia: Datos ya cargados el dÃ­a de hoy en '{table_name_hist}'.")
                    else:
                        raise ex
        
        except Exception as e:
            raise e
        
        # Si todo saliÃ³ bien
        return True, "Â¡Proceso completado con Ã©xito!"

    except Exception as e:
        error_message = str(e).lower() 
        
        if "authentication failed" in error_message or "connection to server" in error_message or "duplicate sasl authentication" in error_message:
            
            return False, "âŒ Â¡Error de conexiÃ³n! Revisa tu Host, Usuario, ContraseÃ±a y Nombre de Base de Datos."

        elif "worksheet named" in error_message and "not found" in error_message:
            return False, "âŒ Error de Excel: No se encontrÃ³ la hoja 'resultados_por_lotes_finales' en el archivo que subiste. Por favor, revisa el archivo."

        elif "specify an engine manually" in error_message:
            return False, "âŒ Error de Archivo: El formato de Excel .xls no es compatible. Por favor, abre el archivo en Excel y guÃ¡rdalo como .xlsx antes de subirlo."
        
        elif "relation" in error_message and "does not exist" in error_message:
            return False, f"âŒ Error de Base de Datos: Una de las tablas no existe. (Detalle: {e})"
            
        else:
            st.error(f"Error detallado: {e}")
            return False, f"Error general en el procesamiento: {e}"

# -----------------------------------------------------------------
# 2. LA INTERFAZ WEB (EL FRONT-END)
# -----------------------------------------------------------------
st.set_page_config(layout="centered", page_title="AnÃ¡lisis de inversiones")
st.title("ðŸ’° AnÃ¡lisis de inversiones")
st.write("Sube tu reporte de Balanz y completa los datos de tu Base de Datos de Supabase (PostgreSQL).")
st.write("El reporte a utilizar corresponde a 'Resultados del periodo' e informe 'Completo'")

# --- Formulario de Carga ---
with st.form(key="upload_form"):
    
    # A. El cargador de archivos
    uploaded_file = st.file_uploader("1. Sube tu archivo (Excel)", type=["xlsx"])
    
    st.divider()
    
    # B. Las credenciales de la DB
    st.subheader("2. Credenciales de tu Base de Datos (Supabase)")
    st.markdown("Â¿No tienes base de datos? [RegÃ­strate en Supabase aquÃ­](https://supabase.com/dashboard/sign-up)")
    col1, col2 = st.columns(2)
    with col1:
        db_host = st.text_input("Host (Servidor)", placeholder="db.xxxxxxxx.supabase.co")
        db_user = st.text_input("Usuario")
    with col2:
        db_name = st.text_input("Nombre de la Base de Datos", "postgres")
        db_pass = st.text_input("ContraseÃ±a", type="password")

    st.divider()

    # C. El botÃ³n de envÃ­o
    submit_button = st.form_submit_button(
        label="ðŸš€ Procesar y Cargar Datos", 
        use_container_width=True
    )

# --- LÃ³gica de Procesamiento (se ejecuta al apretar el botÃ³n) ---
if submit_button:

    st.session_state.procesamiento_listo = False
    
    # Verificamos que todos los campos estÃ©n completos
    if uploaded_file is not None and db_host and db_name and db_user and db_pass:
        
        # Muestra el "spinner" mientras la funciÃ³n se ejecuta
        with st.spinner('Procesando archivo y conectando a Supabase... Esto puede tardar varios segundos...'):
            
            # Llama a tu funciÃ³n de lÃ³gica
            exito, mensaje = procesar_y_guardar_en_sql(
                uploaded_file, 
                db_host, 
                db_name, 
                db_user, 
                db_pass
            )
        
        # Muestra el resultado
        if exito:
            st.session_state.procesamiento_listo = True
            st.session_state.ultimo_mensaje = mensaje
            st.success(mensaje)
            
            # --- 3. BOTÃ“N DE DESCARGA DE POWER BI ---
            st.subheader("Â¡Tus datos estÃ¡n listos!")
            st.write("El siguiente paso es descargar tu plantilla de Power BI. Ãbrela, introduce tus credenciales de Supabase (las mismas que usaste aquÃ­) y haz clic en 'Actualizar'.")
            
            # Nombre de tu plantilla. DEBE estar en la misma carpeta que este script.
            template_file_name = "Plantilla_PowerBI.pbit" 
            
            # Verificamos si el archivo existe antes de mostrar el botÃ³n
            if os.path.exists(template_file_name):
                with open(template_file_name, "rb") as f:
                    file_data = f.read()
                
                st.download_button(
                    label="ðŸ“¥ Descargar Plantilla de Power BI (.pbit)",
                    data=file_data,
                    file_name=template_file_name,
                    mime="application/vnd.ms-powerbi.template",
                    use_container_width=True
                )
            else:
                st.error(f"Error de configuraciÃ³n: No se encontrÃ³ el archivo '{template_file_name}' en el servidor.")
                st.warning("AsegÃºrate de haber subido el archivo .pbit a la carpeta de la aplicaciÃ³n.")
                st.session_state.procesamiento_listo = False
                
        else:
            # Si 'exito' es False, muestra el mensaje de error
            st.error(mensaje)
            
    else:
        # Si faltan campos
        st.warning("Por favor, completa TODOS los campos y sube un archivo.")



























